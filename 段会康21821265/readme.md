## Personal information：
 **name**: 段会康
 
 **student id**: 21821265
 
 **email**: 884957043@qq.com
 


## Schedule:

|Task|Due|Done|
|---|---|---|
|选择论文|Mar.14|√|
|精度论文|Mar.21|√|
|复现论文|Apr.4| |
|完成对比实验|Apr.11| |
|完成报告|Apr.18| |


## 选择论文:
### title:
Text-Independent Speaker Verification Based on Triplet Convolutional Neural Network Embeddings

选自：IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2018

### abstract:
The effectiveness of introducing deep neural networks into conventional speaker recognition pipelines has been broadly shown to benefit
system performance. A novel text-independent speaker verification(SV) framework based on the triplet loss and a very deepconvolutional
neural network architecture (i.e., Inception-Resnet-v1) are investigated in this study, where a fixed length speaker discriminative
embedding is learned from sparse speech features and utilized as a feature representation for the SV tasks. A concise description of
the neural network-based speaker discriminative training with triplet loss is presented. An Euclidean distance similarity metric is
applied in both network training and SV testing, which ensures the SV system to follow an end-to-end fashion. By replacing the final
max/average pooling layer with a spatial pyramid pooling layer in the Inception-Resnet-v1 architecture, the fixed-length input
constraint is relaxed and an obvious performance gain is achieved compared with the fixed-length input speaker embedding system. For
datasets with more severe training/test condition mismatches, the probabilistic linear discriminant analysis (PLDA) back end is further
introduced to replace the distance-based scoring for the proposed speaker embedding system. Thus, we reconstruct the SV task with a
neural network based front-end speaker embedding system and a PLDA that provides channel and noise variabilities compensation in the
back end. Extensive experiments are conducted to provide useful hints that lead to a better testing performance. Comparison with the
state-of-the-art SV frameworks on three public datasets (i.e., a prompt speech corpus, a conversational speech Switchboard corpus, and
NIST SRE10 10 s–10 s condition) justifies the effectiveness of our proposed speaker embedding system



## 精读论文：

见：精读论文.pdf
## 复现论文：


## 对比试验：


## 完成报告：

